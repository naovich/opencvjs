<!DOCTYPE html>
<html lang="fr">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Détection de visage avec extrapolation de la carte</title>
    <style>
      body {
        font-family: Arial, sans-serif;
        max-width: 1200px;
        margin: 0 auto;
        padding: 20px;
      }
      .container {
        display: flex;
        gap: 20px;
        margin: 20px 0;
      }
      .video-section {
        flex: 1;
        position: relative;
      }
      .result-section {
        flex: 1;
      }
      .controls {
        margin: 10px 0;
      }
      button {
        padding: 10px 20px;
        font-size: 16px;
        cursor: pointer;
      }
      #overlay-rectangle {
        position: absolute;
        border: 2px solid orange;
        pointer-events: none;
        top: 50%;
        left: 50%;
        transform: translate(-50%, -50%);
      }
      .nav-menu {
        background-color: #333;
        padding: 15px 0;
        margin-bottom: 20px;
      }
      .nav-menu ul {
        list-style-type: none;
        margin: 0;
        padding: 0;
        display: flex;
        justify-content: center;
        gap: 20px;
      }
      .nav-menu a {
        color: white;
        text-decoration: none;
        font-size: 16px;
        padding: 8px 15px;
        border-radius: 4px;
        transition: background-color 0.3s;
      }
      .nav-menu a:hover {
        background-color: #555;
      }
      .nav-menu a.active {
        background-color: #4caf50;
      }
    </style>
  </head>
  <body>
    <nav class="nav-menu">
      <ul>
        <li><a href="index.html">Analyse d'image</a></li>
        <li><a href="face.html">Face recognition</a></li>
        <li>
          <a href="facePlusCardaprox.html">Face et carte</a>
        </li>
        <li>
          <a href="faceEyesCard.html" class="active">Face, carte et eyes</a>
        </li>
        <li><a href="faceCardAproxContour.html">Face, carte et contour</a></li>
      </ul>
    </nav>
    <h1>Détection de visage et extrapolation de la carte</h1>
    <div class="container">
      <div class="video-section" style="display: none">
        <video id="video" width="640" height="480" autoplay></video>
        <div id="overlay-rectangle"></div>
        <div class="controls">
          <button id="toggleOverlay">Afficher/Masquer le guide</button>
        </div>
      </div>
      <div class="result-section">
        <canvas
          id="canvas"
          width="640"
          height="480"
          willReadFrequently="true"
        ></canvas>
      </div>
    </div>
    <script>
      let video = document.getElementById("video");
      let canvas = document.getElementById("canvas");
      let context = canvas.getContext("2d");
      let openCv = null;
      let faceClassifier = null;
      let isOverlayVisible = false;

      navigator.mediaDevices
        .getUserMedia({ video: true })
        .then((stream) => {
          video.srcObject = stream;
        })
        .catch((err) => {
          console.error("Erreur lors de l'accès à la caméra: " + err);
        });

      async function loadCascadeClassifier() {
        const response = await fetch(
          "src/classifiers/haarcascade_frontalface_default.xml"
        );
        const buffer = await response.arrayBuffer();
        const data = new Uint8Array(buffer);
        openCv.FS_createDataFile(
          "/",
          "haarcascade_frontalface_default.xml",
          data,
          true,
          false,
          false
        );
        let classifier = new openCv.CascadeClassifier();
        classifier.load("haarcascade_frontalface_default.xml");
        return classifier;
      }

      // Détection du visage et dessin du rectangle rouge
      // Retourne un objet contenant le rectangle du visage et la Mat avec le rectangle dessiné
      async function faceDetection() {
        context.drawImage(video, 0, 0, canvas.width, canvas.height);
        let src = openCv.imread(canvas);
        let gray = new openCv.Mat();
        openCv.cvtColor(src, gray, openCv.COLOR_RGBA2GRAY);

        if (!faceClassifier) {
          faceClassifier = await loadCascadeClassifier();
        }
        let faces = new openCv.RectVector();
        faceClassifier.detectMultiScale(gray, faces, 1.3, 7, 0);
        let faceRect = null;
        if (faces.size() > 0) {
          let face = faces.get(0);
          faceRect = {
            x: face.x,
            y: face.y,
            width: face.width,
            height: face.height,
          };
          let pt1 = new openCv.Point(face.x, face.y);
          let pt2 = new openCv.Point(face.x + face.width, face.y + face.height);
          openCv.rectangle(src, pt1, pt2, [255, 0, 0, 255], 2);
        }
        gray.delete();
        faces.delete();
        return { faceRect, src };
      }

      // Fonction pour charger le classificateur Haar pour les yeux
      async function loadEyeCascadeClassifier() {
        const response = await fetch("src/classifiers/haarcascade_eye.xml");
        const buffer = await response.arrayBuffer();
        const data = new Uint8Array(buffer);
        openCv.FS_createDataFile(
          "/",
          "haarcascade_eye.xml",
          data,
          true,
          false,
          false
        );
        let classifier = new openCv.CascadeClassifier();
        classifier.load("haarcascade_eye.xml");
        return classifier;
      }

      // Fonction pour détecter les yeux dans la région du visage
      // 'src' est la Mat de l'image complète et 'faceRect' est le rectangle (object {x, y, width, height})
      // qui correspond à la détection du visage.
      async function eyeDetection(src, faceRect) {
        // Si aucun visage n'est détecté, on ne fait rien.
        if (!faceRect) return;

        // Extraire la région d'intérêt (ROI) correspondant au visage
        let faceROI = src.roi(
          new openCv.Rect(
            faceRect.x,
            faceRect.y,
            faceRect.width,
            faceRect.height
          )
        );
        let grayFace = new openCv.Mat();
        openCv.cvtColor(faceROI, grayFace, openCv.COLOR_RGBA2GRAY);

        // Charger le classificateur pour les yeux (stocké dans une variable globale par exemple)
        if (!window.eyeClassifier) {
          window.eyeClassifier = await loadEyeCascadeClassifier();
        }
        let eyes = new openCv.RectVector();
        // Détection des yeux dans la ROI du visage
        window.eyeClassifier.detectMultiScale(grayFace, eyes, 1.1, 3, 0);

        // Pour chaque œil détecté, tracer un rectangle violet sur l'image source
        for (let i = 0; i < eyes.size(); i++) {
          let eye = eyes.get(i);
          // Convertir les coordonnées relatives à la ROI en coordonnées de l'image complète
          let eyeRect = new openCv.Rect(
            faceRect.x + eye.x,
            faceRect.y + eye.y,
            eye.width,
            eye.height
          );
          let pt1 = new openCv.Point(eyeRect.x, eyeRect.y);
          let pt2 = new openCv.Point(
            eyeRect.x + eyeRect.width,
            eyeRect.y + eyeRect.height
          );
          // Utilisation d'une couleur violette (par exemple [238, 130, 238, 255])
          openCv.rectangle(src, pt1, pt2, [238, 130, 238, 255], 2);
        }

        // Nettoyage
        eyes.delete();
        grayFace.delete();
        faceROI.delete();
      }

      // Extrapolation du rectangle de la carte à partir du rectangle du visage
      function extrapolateCardRectangle(faceRect) {
        // On suppose que le visage occupe environ 60 % de la hauteur de la carte.
        const s = 3.5; // facteur d'échelle
        const offsetX = -15; // décalage par rapport au bord gauche du visage
        const offsetY = -10; // décalage par rapport au centre du visage
        let cardHeight = faceRect.height * s;
        let cardWidth = cardHeight * (85.6 / 53.98); // Ratio ISO 7810 ≃ 1.586
        let cardX = faceRect.x - faceRect.width * 0.4 + offsetX; // le bord gauche du visage correspond au bord gauche de la carte
        let faceCenterY = faceRect.y + faceRect.height / 2;
        let cardY = faceCenterY - cardHeight / 2 + offsetY;
        return { x: cardX, y: cardY, width: cardWidth, height: cardHeight };
      }

      // Fonction pour tracer un rectangle (ici pour la carte, en orange)
      function drawRectangle(src, rect, color, thickness) {
        let pt1 = new openCv.Point(rect.x, rect.y);
        let pt2 = new openCv.Point(rect.x + rect.width, rect.y + rect.height);
        openCv.rectangle(src, pt1, pt2, color, thickness);
      }

      async function processFrame() {
        // Appel de la détection du visage qui retourne la Mat avec le rectangle rouge déjà dessiné
        let faceResult = await faceDetection();
        let faceRect = faceResult.faceRect;
        let src = faceResult.src;
        if (faceRect) {
          await eyeDetection(src, faceRect);

          // Extrapolation du rectangle de la carte et tracé en orange
          let cardRect = extrapolateCardRectangle(faceRect);
          drawRectangle(src, cardRect, [255, 165, 0, 255], 2);
        }
        openCv.imshow(canvas, src);
        src.delete();
      }

      async function mainLoop() {
        if (!openCv) {
          requestAnimationFrame(mainLoop);
          return;
        }
        await processFrame();
        requestAnimationFrame(mainLoop);
      }

      async function onOpenCvReady() {
        console.log("OpenCV.js est prêt.");
        openCv = await cv;
        requestAnimationFrame(mainLoop);
      }

      document.getElementById("toggleOverlay").addEventListener("click", () => {
        const overlay = document.getElementById("overlay-rectangle");
        overlay.style.display =
          overlay.style.display === "none" || overlay.style.display === ""
            ? "block"
            : "none";
      });
    </script>
    <script
      async
      src="https://docs.opencv.org/4.11.0/opencv.js"
      onload="onOpenCvReady();"
    ></script>
  </body>
</html>
